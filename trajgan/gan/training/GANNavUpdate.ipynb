{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "#from skimage.util import random_noise\\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting all the files now...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# This is for the images to unzip the file in the directory\n",
    "# importing required modules\n",
    "from zipfile import ZipFile\n",
    "\n",
    "# specifying the zip file name\n",
    "file_name = \"Archive.zip\"\n",
    "\n",
    "# opening the zip file in READ mode\n",
    "with ZipFile(file_name, 'r') as zip:\n",
    "\n",
    "    # extracting all the files\n",
    "    print('Extracting all the files now...')\n",
    "    zip.extractall()\n",
    "    print('Done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_files</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>..\\..\\..\\data\\preproc\\preproc_test_image221307...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>..\\..\\..\\data\\preproc\\preproc_test_image221308...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>..\\..\\..\\data\\preproc\\preproc_test_image221309...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>..\\..\\..\\data\\preproc\\preproc_test_image221310...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>..\\..\\..\\data\\preproc\\preproc_test_image221311...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           img_files\n",
       "0  ..\\..\\..\\data\\preproc\\preproc_test_image221307...\n",
       "1  ..\\..\\..\\data\\preproc\\preproc_test_image221308...\n",
       "2  ..\\..\\..\\data\\preproc\\preproc_test_image221309...\n",
       "3  ..\\..\\..\\data\\preproc\\preproc_test_image221310...\n",
       "4  ..\\..\\..\\data\\preproc\\preproc_test_image221311..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transforming a Folder of images into csv File\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "DATA_DIR = os.path.join('..', '..', '..', 'data')\n",
    "train_folder = os.path.join(DATA_DIR, 'preproc')\n",
    "#train_annotation = BASE_DIR+'annotated_train_data/'\n",
    "\n",
    "#files_in_train = sorted(os.listdir(train_folder))\n",
    "#files_in_annotated = sorted(os.listdir(train_annotation))\n",
    "\n",
    "train_files = [i for i in os.listdir(train_folder) if i.endswith('.png')]\n",
    "# images \n",
    "\n",
    "df = pd.DataFrame()\n",
    "# df['images'] = [train_folder+str(x) for x in images]\n",
    "df['img_files'] = [os.path.join(train_folder, i) for i in train_files]\n",
    "#df['labels']=[train_annotation+str(x) for x in images]\n",
    "df.head()\n",
    "# print(os.path.isfile(df['img_files'][20]))\n",
    "# pd.to_csv('files_path.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete the following block of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c9f62a402a04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mread_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mCustomImageDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotations_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotations_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# Creating the images dataset using resource: \n",
    "# https://towardsdatascience.com/building-efficient-custom-datasets-in-pytorch-2563b946fd9f\n",
    "# https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
    "# import os\n",
    "# import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = read_image(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        sample = {\"image\": image, \"label\": label}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'beta1': 0.5, 'beta2': 0.999,'lr_g':0.0009,'lr_d':0.0009,'max_epochs':5} \n",
    "params['z_dim'] =2\n",
    "params['base_size'] = 64 \n",
    "\n",
    "gan = CustomImageDataset(params)\n",
    "gan.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start - Code to keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 1.60000041e+00, 3.20000051e+00, 4.80000222e+00,\n",
       "       6.39999617e+00, 8.00001058e+00, 9.59999118e+00, 1.12000046e+01,\n",
       "       1.27999982e+01, 1.44000007e+01, 1.60000000e+01, 9.93500000e-03,\n",
       "       1.99192300e-02, 2.96465600e-02, 4.06126700e-02, 4.83113900e-02,\n",
       "       6.14106900e-02, 6.92593700e-02, 8.02891900e-02, 8.98933200e-02])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BeBot_df = pd.read_csv(os.path.join(DATA_DIR, 'data.csv'), names=['x', 'y', 'tf', 'img_name'], header=None)\n",
    "BeBot_df.head()\n",
    "\n",
    "def read_bebot_data(bebot_df):\n",
    "    \"\"\"Reads the BeBOT dataframe and converts it to a dictionary\n",
    "    \n",
    "    RETURNS\n",
    "        dict('img_name', np.array) - where 'img_name' is a string containing the image name associated with the data and np.array is a numpy array of [x0, ..., xn, y0, ..., yn, tf]\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for traj in bebot_df.iterrows():\n",
    "        tmp = [float(i.strip(' []')) for i in traj[1]['x'].split()[1:-1]]\n",
    "        tmp += [float(i.strip(' []')) for i in traj[1]['y'].split()[1:-1]]\n",
    "        tmp += [traj[1]['tf']]\n",
    "        tmp += [i.strip(' []') for i in traj[1]['img_name'].split()]\n",
    "        data.append(tmp)\n",
    "        \n",
    "    data_dict = dict(zip([i[-1] for i in data], [np.array(i[:-1]) for i in data]))\n",
    "    return data_dict\n",
    "\n",
    "bebot_data = read_bebot_data(BeBot_df)\n",
    "bebot_data['image221308'][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def visualize_training_data(traj_data, img_data):\n",
    " \n",
    "#     for traj in traj_data.iterrows():\n",
    "#         print(traj[0])\n",
    "        \n",
    "# visualize_training_data(BeBot_data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [float(i.strip(' []')) for i in BeBot_data['x'][0].split()[1:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test2 = dict(zip([i[-1] for i in test], [i[:-1] for i in test]))\n",
    "# test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp = pd.read_csv(os.path.join(DATA_DIR, 'data.csv'), names=['x', 'y', 'tf', 'img_name'], header=None, converters={'x': literal_eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class generator(nn.Module):\n",
    "    # Network Architecture based on infoGAN (https://arxiv.org/abs/1606.03657)\n",
    "    def __init__(self, input_dim=100, output_dim=3, input_size=32,base_size=64):\n",
    "        super(generator, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.input_size = input_size\n",
    "        self.base_size = base_size\n",
    "\n",
    "        self.cn = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 2*self.base_size * (self.input_size // 4) * (self.input_size // 4)),\n",
    "            nn.BatchNorm1d(2*self.base_size * (self.input_size // 4) * (self.input_size // 4)),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.deconv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(2*self.base_size, self.base_size, 4, 2, 1),\n",
    "            nn.BatchNorm2d(self.base_size),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(self.base_size, self.output_dim, 4, 2, 1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        initialize_weights(self)\n",
    "\n",
    "        self.l1 = nn.Linear(2,10)\n",
    "        self.l2 = nn.Linear(10, 10)\n",
    "        self.l3 = nn.Linear(10,3)\n",
    "        self.fc = nn.Linear(6, 6)\n",
    "\n",
    "    def forward(self, input, y):\n",
    "        x = self.cn(input)\n",
    "        print(x.shape)\n",
    "        x = x.view(-1, 2*self.base_size, (self.input_size // 4), (self.input_size // 4))\n",
    "        print(x.shape)\n",
    "        x = self.deconv(x)\n",
    "        print(x.shape)\n",
    "        y = self.l1(y)\n",
    "        print(x.shape)\n",
    "        y = self.l2(y)\n",
    "        print(x.shape)\n",
    "        y = self.l3(y)\n",
    "        print(x.shape)\n",
    "        z = torch.cat([x,y],1)\n",
    "        print(x.shape)\n",
    "        z = self.fc(z)\n",
    "\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class discriminator(nn.Module):\n",
    "    # Network Architecture is exactly same as in infoGAN (https://arxiv.org/abs/1606.03657)\n",
    "    # Architecture : (64)4c2s-(128)4c2s_BL-FC1024_BL-FC1_S\n",
    "    def __init__(self, input_dim=1, output_dim=1, input_size=32,base_size=64):\n",
    "        super(discriminator, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.input_size = 28\n",
    "        self.base_size = base_size\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(self.input_dim, self.base_size, 4, 2, 1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(self.base_size, 2*self.base_size, 4, 2, 1),\n",
    "            nn.BatchNorm2d(2*self.base_size),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(2*self.base_size * (self.input_size // 4) * (self.input_size // 4), 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(1024, self.output_dim),  # Note: no activation at the output.\n",
    "        )\n",
    "        initialize_weights(self)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.conv(input)\n",
    "        x = x.view(-1, 2*self.base_size * (self.input_size // 4) * (self.input_size // 4))\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(net):\n",
    "    for m in net.modules():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            m.weight.data.normal_(0, 0.02)\n",
    "            m.bias.data.zero_()\n",
    "        elif isinstance(m, nn.ConvTranspose2d):\n",
    "            m.weight.data.normal_(0, 0.02)\n",
    "            m.bias.data.zero_()\n",
    "        elif isinstance(m, nn.Linear):\n",
    "            m.weight.data.normal_(0, 0.02)\n",
    "            m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN():\n",
    "    def __init__(self, params):\n",
    "        \"\"\"Generative Adversarial Network class for learning how to control a self driving car with Bernstein polynomials\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        params : dict\n",
    "            Dictionary containing the parameters of the problem.\n",
    "                * max_epochs - Maximum number of epochs\n",
    "                * z_dim\n",
    "                * base_size\n",
    "                * lr_g - Generator learning rate\n",
    "                * lr_d - Discriminator learning rate\n",
    "                * beta1\n",
    "                * beta2\n",
    "        Returns\n",
    "        -------\n",
    "        numpy.array\n",
    "            1D vectory containing the initial guess for the optimizer. See above\n",
    "            description for the layout of the vector.\n",
    "        \"\"\"\n",
    "        # parameters\n",
    "        self.epoch = params['max_epochs']\n",
    "        self.sample_num = 100\n",
    "        self.batch_size = 300\n",
    "        self.input_size = 300\n",
    "        self.z_dim = params['z_dim']\n",
    "        self.base_size = params['base_size']\n",
    "\n",
    "        # load dataset\n",
    "#         self.data_loader = torch.utils.data.DataLoader(mnist_data_reduced, \n",
    "#                                                batch_size=self.batch_size, \n",
    "#                                                shuffle=True)\n",
    "        self.create_data_loader()\n",
    "        data = self.data_loader.__iter__().__next__()[0]\n",
    "\n",
    "        # initialization of the generator and discriminator\n",
    "        self.G = generator(input_dim=self.z_dim, output_dim=data.shape[1], input_size=self.input_size,base_size=self.base_size).cuda()\n",
    "        self.D = discriminator(input_dim=data.shape[1], output_dim=1, input_size=self.input_size,base_size=self.base_size).cuda()\n",
    "        self.G_optimizer = optim.Adam(self.G.parameters(), lr=params['lr_g'], betas=(params['beta1'], params['beta2']))\n",
    "        self.D_optimizer = optim.Adam(self.D.parameters(), lr=params['lr_d'], betas=(params['beta1'], params['beta2']))\n",
    "        #self.G_optimizer = optim.SGD(self.G.parameters(), lr=params['lr_g'], momentum=0.9)\n",
    "        #self.D_optimizer = optim.SGD(self.D.parameters(), lr=params['lr_d'], momentum=0.9)\n",
    "        \n",
    "        # initialization of the loss function\n",
    "        self.BCE_loss = nn.BCELoss().cuda()\n",
    "        self.MSE_loss = nn.MSELoss().cuda()\n",
    "        \n",
    "        # Gettng a batch of noise to generate the fake data\n",
    "        self.sample_z_ = torch.rand((self.batch_size, self.z_dim)).cuda()\n",
    "        \n",
    "    def create_data_loader(self):\n",
    "        self.data_loader = torch.utils.data.DataLoader(mnist_data_reduced, \n",
    "                                                       batch_size=self.batch_size, \n",
    "                                                       shuffle=True)\n",
    "        \n",
    "    #--------------------------------------------------------------------------------------------------------\n",
    "    # Fucntion to train the GAN, where you alternate between the training of the genenator and discriminator\n",
    "    def train(self):\n",
    "\n",
    "       # Setting empty arrays for storing the losses\n",
    "        self.train_hist = {}\n",
    "        self.train_hist['D_loss'] = []\n",
    "        self.train_hist['G_loss'] = []\n",
    "\n",
    "        # Setting up the labels for real and fake images\n",
    "        self.y_real_, self.y_fake_ = torch.ones(self.batch_size, 1).cuda(), torch.zeros(self.batch_size, 1).cuda()\n",
    "        \n",
    "        print('training start!!')\n",
    "\n",
    "        # Epoch loops\n",
    "        for epoch in range(self.epoch):\n",
    "            epoch_start_time = time.time()\n",
    "\n",
    "\n",
    "            for iter, (x_, _) in enumerate(self.data_loader):\n",
    "                if iter == self.data_loader.dataset.__len__() // self.batch_size:\n",
    "                    break\n",
    "\n",
    "                # Generate random noise to push through the generator   \n",
    "                z_ = torch.rand((self.batch_size, self.z_dim))\n",
    "                x_, z_ = x_.cuda(), z_.cuda()\n",
    "\n",
    "                # update D network\n",
    "                for i in range(Ninner):\n",
    "                    self.D_optimizer.zero_grad()\n",
    "                    x_ = x_  + 0.025 * torch.randn(x_.shape).cuda()\n",
    "                    D_real = self.D(x_)\n",
    "                    D_real_loss = self.BCE_loss(D_real, self.y_real_)\n",
    "\n",
    "                    G_ = self.G(z_)\n",
    "                    D_fake = self.D(G_)\n",
    "                    D_fake_loss = self.BCE_loss(D_fake, self.y_fake_)\n",
    "\n",
    "                    D_loss = D_real_loss + D_fake_loss\n",
    "                    D_loss.backward()\n",
    "                    self.D_optimizer.step()    \n",
    "\n",
    "                # update G network\n",
    "                for i in range(Ninner):\n",
    "                    self.G_optimizer.zero_grad()\n",
    "                    G_ = self.G(z_)\n",
    "                    D_fake = self.D(G_)\n",
    "                    G_loss = self.BCE_loss(D_fake, self.y_real_)\n",
    "\n",
    "                    G_loss.backward()\n",
    "                    self.G_optimizer.step()\n",
    "\n",
    "                self.train_hist['D_loss'].append(D_loss.item())\n",
    "                self.train_hist['G_loss'].append(G_loss.item())\n",
    "\n",
    "                # Print iterations and losses\n",
    "                if ((iter + 1) % 50) == 0:\n",
    "                    print(\"Epoch: [%2d] [%4d/%4d] D_loss: %.8f, G_loss: %.8f\" %\n",
    "                    ((epoch + 1), (iter + 1), self.data_loader.dataset.__len__() // self.batch_size, D_loss.item(), G_loss.item()))\n",
    "                \n",
    "            # Visualize results\n",
    "            with torch.no_grad():\n",
    "                visualize_results(self)\n",
    "\n",
    "        print(\"Training finished!\")\n",
    "\n",
    "    def train_ae(self):\n",
    "        torch.manual_seed(42)\n",
    "        criterion = nn.MSELoss() # mean square error loss\n",
    "        #optimizer = torch.optim.Adam(\n",
    "            #model.params(), lr=learning_rate, weight_decay=1e-4)\n",
    "\n",
    "        #train_loader = torch.utils.data.DataLoader(mnist_data_reduced, \n",
    "                                                  #batch_size=batch_size, \n",
    "                                                  #shuffle=True)\n",
    "        models = []\n",
    "        for epoch in range(self.epoch):\n",
    "            for data in self.data_loader:\n",
    "                img, _ = data\n",
    "                img = Variable(img).cuda().type(torch.cuda.FloatTensor)\n",
    "                recon = self.G(self.D(img))\n",
    "                loss = criterion(recon, img)\n",
    "                self.D_optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.D_optimizer.step()\n",
    "        \n",
    "            # Saving the models at each epoch for visualization purposes\n",
    "            #fname = 'dict'+str(epoch)\n",
    "            #torch.save(model.state_dict(), fname)\n",
    "            print('Epoch:{}, Loss:{:.4f}'.format(epoch+1, float(loss))) \n",
    "\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mnist_data_reduced' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-0fa687994f5f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'base_size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mgan\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGAN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mgan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-24-c07a90cbe572>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;31m# load dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         self.data_loader = torch.utils.data.DataLoader(mnist_data_reduced, \n\u001b[0m\u001b[0;32m     13\u001b[0m                                                \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                                                shuffle=True)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mnist_data_reduced' is not defined"
     ]
    }
   ],
   "source": [
    "params = {'beta1': 0.5, 'beta2': 0.999,'lr_g':0.0009,'lr_d':0.0009,'max_epochs':5} \n",
    "params['z_dim'] =2\n",
    "params['base_size'] = 64 \n",
    "\n",
    "gan = GAN(params)\n",
    "gan.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
