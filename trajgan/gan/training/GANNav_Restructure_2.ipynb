{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.io import read_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the preprocessed file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_files</th>\n",
       "      <th>img_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training_data/train_data/preproc_test_image017...</td>\n",
       "      <td>preproc_test_image017249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>training_data/train_data/preproc_test_image018...</td>\n",
       "      <td>preproc_test_image018393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>training_data/train_data/preproc_test_image017...</td>\n",
       "      <td>preproc_test_image017881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>training_data/train_data/preproc_test_image017...</td>\n",
       "      <td>preproc_test_image017117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>training_data/train_data/preproc_test_image018...</td>\n",
       "      <td>preproc_test_image018230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           img_files                  img_name\n",
       "0  training_data/train_data/preproc_test_image017...  preproc_test_image017249\n",
       "1  training_data/train_data/preproc_test_image018...  preproc_test_image018393\n",
       "2  training_data/train_data/preproc_test_image017...  preproc_test_image017881\n",
       "3  training_data/train_data/preproc_test_image017...  preproc_test_image017117\n",
       "4  training_data/train_data/preproc_test_image018...  preproc_test_image018230"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transforming a Folder of images into csv File\n",
    "try:\n",
    "    DATA_DIR = os.path.join('training_data')\n",
    "except:\n",
    "    raise RuntimeError('Error for the training_data directory')\n",
    "\n",
    "try:\n",
    "    train_folder = os.path.join(DATA_DIR, 'train_data')\n",
    "except:\n",
    "    raise RuntimeError('Error for the train_data directory')\n",
    "\n",
    "\n",
    "#print(os.path.abspath('training_data'))\n",
    "#print(train_folder)\n",
    "\n",
    "train_files = [i for i in os.listdir(train_folder) if i.endswith('.png')]\n",
    "Image_name = [i for i in list(train_files)]\n",
    "\n",
    "i=0\n",
    "while i< len(Image_name):\n",
    "    Image_name[i] = Image_name[i][0:24]\n",
    "    i=i+1\n",
    "    \n",
    "    \n",
    "df = pd.DataFrame()\n",
    "df['img_files'] = [os.path.join(train_folder, i) for i in train_files]\n",
    "df['img_name'] = Image_name\n",
    "df.head()\n",
    "                               \n",
    "#print(Image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of        x   y                  img_name\n",
      "0    240  10  preproc_test_image015405\n",
      "1    250  10  preproc_test_image015406\n",
      "2    255  10  preproc_test_image015416\n",
      "3    265  10  preproc_test_image015417\n",
      "4    245  10  preproc_test_image015428\n",
      "..   ...  ..                       ...\n",
      "263  254   2  preproc_test_image024418\n",
      "264  254   1  preproc_test_image024419\n",
      "265  253   1  preproc_test_image024426\n",
      "266  255   1  preproc_test_image024430\n",
      "267  255   4  preproc_test_image024431\n",
      "\n",
      "[268 rows x 3 columns]>\n"
     ]
    }
   ],
   "source": [
    "# Open the dataset \n",
    "controlInput_df = pd.read_csv(os.path.join(DATA_DIR, 'dataset.csv'), names=['x', 'y', 'img_name'], header=None)\n",
    "print(controlInput_df.head)\n",
    "\n",
    "#print(controlInput_df.loc[[3],['y']])\n",
    "# Create variables to better compare with the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CustomDataset(Dataset):\n",
    "\n",
    "#     def __init__(self, csvFile,ImageName, transform=None):\n",
    "#         \"\"\"\n",
    "#         Args:\n",
    "#             csv_file (string): Path to the csv file with annotations.\n",
    "#             root_dir (string): Directory with all the images.\n",
    "#             transform (callable, optional): Optional transform to be applied\n",
    "#                 on a sample.\n",
    "#         \"\"\"\n",
    "#         self.csv_file = csvFile\n",
    "#         #self.root_dir = root_dir\n",
    "#         self.transform = transform\n",
    "#         Image_name = ImageName\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.csv_file)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         if torch.is_tensor(idx):\n",
    "#             idx = idx.tolist()\n",
    "\n",
    "#         img_name = Image_name(idx)\n",
    "#         print(Image_name(2))\n",
    "#         image = io.imread(img_files(idx))\n",
    "#         i=0\n",
    "#         while i< len(self.csv_file)+1:\n",
    "#             if img_name == controlInput_df.loc[[i],['img_name']]:\n",
    "#                 xPosition = controlInput_df.loc[[i],['x']]\n",
    "#                 yPosition = controlInput_df.loc[[i],['y']]\n",
    "#                 sample = {'imageName': image_name, 'image': image,'x':xPosition,'y':yPosition}\n",
    "#             #landmarks = np.array([landmarks])\n",
    "#             #landmarks = landmarks.astype('float').reshape(-1, 2)\n",
    "#             i =i+1\n",
    "        \n",
    "\n",
    "#         if self.transform:\n",
    "#             sample = self.transform(sample)\n",
    "\n",
    "#         return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.CustomDataset object at 0x7faee8448190>\n"
     ]
    }
   ],
   "source": [
    "custom_dataset = CustomDataset(csvFile=controlInput_df,ImageName=Image_name)\n",
    "print(custom_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'list' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-305ef798a2b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustom_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'imageName'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-44-1e22fbda2bfc>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mimg_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'list' object is not callable"
     ]
    }
   ],
   "source": [
    "\n",
    "i=0\n",
    "while i< len(self.csv_file)+1:\n",
    "    if img_name == controlInput_df.loc[[i],['img_name']]:\n",
    "        xPosition = controlInput_df.loc[[i],['x']]\n",
    "        yPosition = controlInput_df.loc[[i],['y']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and convert the BeBOT trajectory data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   x  \\\n",
      "0  [250.         250.         250.         250.  ...   \n",
      "1  [250.         249.         248.         247.  ...   \n",
      "2  [250.        251.        252.        253.     ...   \n",
      "3  [250.         251.         252.         253.  ...   \n",
      "4  [250.        252.        254.        256.     ...   \n",
      "\n",
      "                                                   y     img_name  \n",
      "0  [480.         433.         386.         339.  ...  image221307  \n",
      "1  [480.         433.5        387.         340.5 ...  image221308  \n",
      "2  [480.         433.         386.         339.  ...  image221309  \n",
      "3  [480.         432.8        385.6        338.4 ...  image221310  \n",
      "4  [480.         433.         386.         339.  ...  image221311  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([250.        , 249.        , 248.        , 247.        ,\n",
       "       246.        , 245.        , 244.        , 243.        ,\n",
       "       242.        , 241.        , 239.99999735, 480.        ,\n",
       "       433.5       , 387.        , 340.5       , 294.        ,\n",
       "       247.5       , 201.        , 154.5       , 108.        ,\n",
       "        61.5       ,  14.99999738])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BeBot_df = pd.read_csv(os.path.join(DATA_DIR, 'data_pix.csv'), names=['x', 'y', 'img_name'], header=None)\n",
    "print(BeBot_df.head())\n",
    "\n",
    "def read_bebot_data(bebot_df):\n",
    "    \"\"\"Reads the BeBOT dataframe and converts it to a dictionary\n",
    "    \n",
    "    RETURNS\n",
    "        dict('img_name', np.array) - where 'img_name' is a string containing the image name associated with the data and np.array is a numpy array of [x0, ..., xn, y0, ..., yn, tf]\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for traj in bebot_df.iterrows():\n",
    "        tmp = [float(i) for i in traj[1]['x'].strip('[]').split()]\n",
    "        tmp += [float(i) for i in traj[1]['y'].strip('[]').split()]\n",
    "#         tmp += [traj[1]['tf']]\n",
    "        tmp += [i.strip(' []') for i in traj[1]['img_name'].split()]\n",
    "        data.append(tmp)\n",
    "        \n",
    "    data_dict = dict(zip([i[-1] for i in data], [np.array(i[:-1]) for i in data]))\n",
    "    return data_dict\n",
    "\n",
    "bebot_data = read_bebot_data(BeBot_df)\n",
    "bebot_data['image221308']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we create the datasets. The variable true_trajs contains the real trajectories generated using BeBOT (i.e. this would be the y_train dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_trajs = DataLoader(TensorDataset(Tensor(np.array(list(bebot_data.values())))), batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class generator(nn.Module):\n",
    "    # Network Architecture based on infoGAN (https://arxiv.org/abs/1606.03657)\n",
    "    def __init__(self, img_channels=3, input_dim=100, output_dim=3, input_size=300, base_size=64):\n",
    "        super(generator, self).__init__()\n",
    "        self.img_channels = img_channels #3 channels for RGB\n",
    "        self.input_dim = input_dim #number of batches\n",
    "        self.output_dim = output_dim #output\n",
    "        self.input_size = input_size #size of the image\n",
    "        self.base_size = base_size \n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            # See https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html for shape info\n",
    "            nn.Conv2d(self.img_channels, self.base_size, 4, stride=2, padding=1), # Output: base_size x 150 x 150\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(self.base_size, 2*self.base_size, 4, stride=2, padding=1), # Output: 2*base_size x 75 x 75\n",
    "            nn.BatchNorm2d(2*self.base_size),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "        \n",
    "        self.cn = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 2*self.base_size * (self.input_size // 4) * (self.input_size // 4)),\n",
    "            nn.BatchNorm1d(2*self.base_size * (self.input_size // 4) * (self.input_size // 4)),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.deconv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(2*self.base_size, self.base_size, 4, 2, 1),\n",
    "            nn.BatchNorm2d(self.base_size),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(self.base_size, self.output_dim, 4, 2, 1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        initialize_weights(self)\n",
    "\n",
    "        self.l1 = nn.Linear(2,10)\n",
    "        self.l2 = nn.Linear(10, 10)\n",
    "        self.l3 = nn.Linear(10,3)\n",
    "        self.fc = nn.Linear(6, 6)\n",
    "\n",
    "    def forward(self, img, pt):\n",
    "#         x = self.cn(input)\n",
    "#         print(x.shape)\n",
    "#         x = x.view(-1, 2*self.base_size, (self.input_size // 4), (self.input_size // 4))\n",
    "#         print(x.shape)\n",
    "#         x = self.deconv(x)\n",
    "#         print(x.shape)\n",
    "#         y = self.l1(y)\n",
    "#         print(x.shape)\n",
    "#         y = self.l2(y)\n",
    "#         print(x.shape)\n",
    "#         y = self.l3(y)\n",
    "#         print(x.shape)\n",
    "#         z = torch.cat([x,y],1)\n",
    "#         print(x.shape)\n",
    "#         z = self.fc(z)\n",
    "        x = self.conv(img)\n",
    "        print(x.shape)\n",
    "        x = x.view(-1, 2*self.base_size * (self.input_size // 4) * (self.input_size // 4))\n",
    "        print(x.shape)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class discriminator(nn.Module):\n",
    "    # Network Architecture is exactly same as in infoGAN (https://arxiv.org/abs/1606.03657)\n",
    "    # Architecture : (64)4c2s-(128)4c2s_BL-FC1024_BL-FC1_S\n",
    "    def __init__(self, input_dim=1, output_dim=1, input_size=32,base_size=64):\n",
    "        super(discriminator, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.input_size = 28\n",
    "        self.base_size = base_size\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(self.input_dim, self.base_size, 4, 2, 1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(self.base_size, 2*self.base_size, 4, 2, 1),\n",
    "            nn.BatchNorm2d(2*self.base_size),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(2*self.base_size * (self.input_size // 4) * (self.input_size // 4), 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(1024, self.output_dim),  # Note: no activation at the output.\n",
    "        )\n",
    "        initialize_weights(self)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.conv(input)\n",
    "        x = x.view(-1, 2*self.base_size * (self.input_size // 4) * (self.input_size // 4))\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(net):\n",
    "    for m in net.modules():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            m.weight.data.normal_(0, 0.02)\n",
    "            m.bias.data.zero_()\n",
    "        elif isinstance(m, nn.ConvTranspose2d):\n",
    "            m.weight.data.normal_(0, 0.02)\n",
    "            m.bias.data.zero_()\n",
    "        elif isinstance(m, nn.Linear):\n",
    "            m.weight.data.normal_(0, 0.02)\n",
    "            m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "219"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_trajs.dataset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN():\n",
    "    def __init__(self, params):\n",
    "        \"\"\"Generative Adversarial Network class for learning how to control a self driving car with Bernstein polynomials\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        params : dict\n",
    "            Dictionary containing the parameters of the problem.\n",
    "                * max_epochs - Maximum number of epochs\n",
    "                * z_dim\n",
    "                * base_size\n",
    "                * lr_g - Generator learning rate\n",
    "                * lr_d - Discriminator learning rate\n",
    "                * beta1\n",
    "                * beta2\n",
    "        Returns\n",
    "        -------\n",
    "        numpy.array\n",
    "            1D vectory containing the initial guess for the optimizer. See above\n",
    "            description for the layout of the vector.\n",
    "        \"\"\"\n",
    "        # parameters\n",
    "        self.epoch = params['max_epochs']\n",
    "        self.sample_num = 100\n",
    "        self.batch_size = 300\n",
    "        self.input_size = 300\n",
    "        self.z_dim = params['z_dim']\n",
    "        self.base_size = params['base_size']\n",
    "\n",
    "#         load dataset\n",
    "#         self.data_loader = torch.utils.data.DataLoader(train_files, \n",
    "#                                                batch_size=self.batch_size, \n",
    "#                                                shuffle=True)\n",
    "#         self.create_data_loader()\n",
    "        data = true_trajs.__iter__().__next__()[0]\n",
    "\n",
    "        # initialization of the generator and discriminator\n",
    "        self.G = generator(input_dim=self.z_dim, output_dim=data.shape[1], input_size=self.input_size,base_size=self.base_size).cuda()\n",
    "        self.D = discriminator(input_dim=data.shape[1], output_dim=1, input_size=self.input_size,base_size=self.base_size).cuda()\n",
    "        self.G_optimizer = optim.Adam(self.G.parameters(), lr=params['lr_g'], betas=(params['beta1'], params['beta2']))\n",
    "        self.D_optimizer = optim.Adam(self.D.parameters(), lr=params['lr_d'], betas=(params['beta1'], params['beta2']))\n",
    "        \n",
    "        # initialization of the loss function\n",
    "        self.BCE_loss = nn.BCELoss().cuda()\n",
    "        self.MSE_loss = nn.MSELoss().cuda()\n",
    "        \n",
    "#     def create_data_loader(self):\n",
    "#         self.data_loader = torch.utils.data.DataLoader(true_trajs, \n",
    "#                                                        batch_size=self.batch_size, \n",
    "#                                                        shuffle=True)\n",
    "        \n",
    "    #--------------------------------------------------------------------------------------------------------\n",
    "    # Fucntion to train the GAN, where you alternate between the training of the genenator and discriminator\n",
    "    def train(self):\n",
    "\n",
    "       # Setting empty arrays for storing the losses\n",
    "        self.train_hist = {}\n",
    "        self.train_hist['D_loss'] = []\n",
    "        self.train_hist['G_loss'] = []\n",
    "\n",
    "        # Setting up the labels for real and fake images\n",
    "        self.y_real_, self.y_fake_ = torch.ones(self.batch_size, 1).cuda(), torch.zeros(self.batch_size, 1).cuda()\n",
    "        \n",
    "        print('training start!!')\n",
    "\n",
    "        # Epoch loops\n",
    "        for epoch in range(self.epoch):\n",
    "            epoch_start_time = time.time()\n",
    "\n",
    "\n",
    "            for iter, (x_) in enumerate(true_trajs):\n",
    "#                 if iter == true_trajs.dataset.__len__() // self.batch_size:\n",
    "#                     print(true_trajs.dataset.__len__() // self.batch_size)\n",
    "#                     print(iter)\n",
    "#                     print('break')\n",
    "#                     break\n",
    "\n",
    "                # Generate random noise to push through the generator   \n",
    "                x_ = x_.cuda()\n",
    "\n",
    "                # update D network\n",
    "                for i in range(Ninner):\n",
    "                    self.D_optimizer.zero_grad()\n",
    "                    x_ = x_  + 0.025 * torch.randn(x_.shape).cuda()\n",
    "                    D_real = self.D(x_)\n",
    "                    D_real_loss = self.BCE_loss(D_real, self.y_real_)\n",
    "\n",
    "                    G_ = self.G(z_)\n",
    "                    D_fake = self.D(G_)\n",
    "                    D_fake_loss = self.BCE_loss(D_fake, self.y_fake_)\n",
    "\n",
    "                    D_loss = D_real_loss + D_fake_loss\n",
    "                    D_loss.backward()\n",
    "                    self.D_optimizer.step()    \n",
    "\n",
    "                # update G network\n",
    "                for i in range(Ninner):\n",
    "                    self.G_optimizer.zero_grad()\n",
    "                    G_ = self.G(z_)\n",
    "                    D_fake = self.D(G_)\n",
    "                    G_loss = self.BCE_loss(D_fake, self.y_real_)\n",
    "\n",
    "                    G_loss.backward()\n",
    "                    self.G_optimizer.step()\n",
    "\n",
    "                self.train_hist['D_loss'].append(D_loss.item())\n",
    "                self.train_hist['G_loss'].append(G_loss.item())\n",
    "\n",
    "                # Print iterations and losses\n",
    "                if ((iter + 1) % 50) == 0:\n",
    "                    print(\"Epoch: [%2d] [%4d/%4d] D_loss: %.8f, G_loss: %.8f\" %\n",
    "                    ((epoch + 1), (iter + 1), true_trajs.dataset.__len__() // self.batch_size, D_loss.item(), G_loss.item()))\n",
    "                \n",
    "#             # Visualize results\n",
    "#             with torch.no_grad():\n",
    "#                 visualize_results(self)\n",
    "\n",
    "        print(\"Training finished!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-0fa687994f5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'base_size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-97a015f967e4>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# initialization of the generator and discriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbase_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbase_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG_optimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr_g'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbetas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'beta1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'beta2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \"\"\"\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \"\"\"\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_cuda_getDeviceCount'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             raise AssertionError(\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "params = {'beta1': 0.5, 'beta2': 0.999,'lr_g':0.0009,'lr_d':0.0009,'max_epochs':5} \n",
    "params['z_dim'] =2\n",
    "params['base_size'] = 64 \n",
    "\n",
    "gan = GAN(params)\n",
    "gan.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
