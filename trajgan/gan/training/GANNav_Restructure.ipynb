{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split, Dataset\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the preprocessed file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_files</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>..\\..\\..\\data\\preproc\\preproc_test_image221307...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>..\\..\\..\\data\\preproc\\preproc_test_image221308...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>..\\..\\..\\data\\preproc\\preproc_test_image221309...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>..\\..\\..\\data\\preproc\\preproc_test_image221310...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>..\\..\\..\\data\\preproc\\preproc_test_image221311...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           img_files\n",
       "0  ..\\..\\..\\data\\preproc\\preproc_test_image221307...\n",
       "1  ..\\..\\..\\data\\preproc\\preproc_test_image221308...\n",
       "2  ..\\..\\..\\data\\preproc\\preproc_test_image221309...\n",
       "3  ..\\..\\..\\data\\preproc\\preproc_test_image221310...\n",
       "4  ..\\..\\..\\data\\preproc\\preproc_test_image221311..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transforming a Folder of images into csv File\n",
    "DATA_DIR = os.path.join('..', '..', '..', 'data')\n",
    "train_folder = os.path.join(DATA_DIR, 'preproc')\n",
    "\n",
    "train_files = [i for i in os.listdir(train_folder) if i.endswith('.png')]\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['img_files'] = [os.path.join(train_folder, i) for i in train_files]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and convert the BeBOT trajectory data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   x  \\\n",
      "0  [250.         250.         250.         250.  ...   \n",
      "1  [250.         249.         248.         247.  ...   \n",
      "2  [250.        251.        252.        253.     ...   \n",
      "3  [250.         251.         252.         253.  ...   \n",
      "4  [250.        252.        254.        256.     ...   \n",
      "\n",
      "                                                   y     img_name  \n",
      "0  [480.         433.         386.         339.  ...  image221307  \n",
      "1  [480.         433.5        387.         340.5 ...  image221308  \n",
      "2  [480.         433.         386.         339.  ...  image221309  \n",
      "3  [480.         432.8        385.6        338.4 ...  image221310  \n",
      "4  [480.         433.         386.         339.  ...  image221311  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([250.        , 249.        , 248.        , 247.        ,\n",
       "       246.        , 245.        , 244.        , 243.        ,\n",
       "       242.        , 241.        , 239.99999735, 480.        ,\n",
       "       433.5       , 387.        , 340.5       , 294.        ,\n",
       "       247.5       , 201.        , 154.5       , 108.        ,\n",
       "        61.5       ,  14.99999738])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BeBot_df = pd.read_csv(os.path.join(DATA_DIR, 'data_pix.csv'), names=['x', 'y', 'img_name'], header=None)\n",
    "print(BeBot_df.head())\n",
    "\n",
    "def read_bebot_data(bebot_df):\n",
    "    \"\"\"Reads the BeBOT dataframe and converts it to a dictionary\n",
    "    \n",
    "    RETURNS\n",
    "        dict('img_name', np.array) - where 'img_name' is a string containing the image name associated with the data and np.array is a numpy array of [x0, ..., xn, y0, ..., yn, tf]\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for traj in bebot_df.iterrows():\n",
    "        tmp = [float(i) for i in traj[1]['x'].strip('[]').split()]\n",
    "        tmp += [float(i) for i in traj[1]['y'].strip('[]').split()]\n",
    "#         tmp += [traj[1]['tf']]\n",
    "        tmp += [i.strip(' []') for i in traj[1]['img_name'].split()]\n",
    "        data.append(tmp)\n",
    "        \n",
    "    data_dict = dict(zip([i[-1] for i in data], [np.array(i[:-1]) for i in data]))\n",
    "    return data_dict\n",
    "\n",
    "bebot_data = read_bebot_data(BeBot_df)\n",
    "bebot_data['image221308']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we create the datasets. The variable true_trajs contains the real trajectories generated using BeBOT (i.e. this would be the y_train dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_trajs = DataLoader(TensorDataset(Tensor(np.array(list(bebot_data.values())))), batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class generator(nn.Module):\n",
    "    # Network Architecture based on infoGAN (https://arxiv.org/abs/1606.03657)\n",
    "    def __init__(self, img_channels=3, input_dim=100, output_dim=3, input_size=300, base_size=64):\n",
    "        super(generator, self).__init__()\n",
    "        self.img_channels = img_channels\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.input_size = input_size\n",
    "        self.base_size = base_size\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            # See https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html for shape info\n",
    "            nn.Conv2d(self.img_channels, self.base_size, 4, stride=2, padding=1), # Output: base_size x 150 x 150\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(self.base_size, 2*self.base_size, 4, stride=2, padding=1), # Output: 2*base_size x 75 x 75\n",
    "            nn.BatchNorm2d(2*self.base_size),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "        \n",
    "        self.cn = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 2*self.base_size * (self.input_size // 4) * (self.input_size // 4)),\n",
    "            nn.BatchNorm1d(2*self.base_size * (self.input_size // 4) * (self.input_size // 4)),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.deconv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(2*self.base_size, self.base_size, 4, 2, 1),\n",
    "            nn.BatchNorm2d(self.base_size),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(self.base_size, self.output_dim, 4, 2, 1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        initialize_weights(self)\n",
    "\n",
    "        self.l1 = nn.Linear(2,10)\n",
    "        self.l2 = nn.Linear(10, 10)\n",
    "        self.l3 = nn.Linear(10,3)\n",
    "        self.fc = nn.Linear(6, 6)\n",
    "\n",
    "    def forward(self, img, pt):\n",
    "#         x = self.cn(input)\n",
    "#         print(x.shape)\n",
    "#         x = x.view(-1, 2*self.base_size, (self.input_size // 4), (self.input_size // 4))\n",
    "#         print(x.shape)\n",
    "#         x = self.deconv(x)\n",
    "#         print(x.shape)\n",
    "#         y = self.l1(y)\n",
    "#         print(x.shape)\n",
    "#         y = self.l2(y)\n",
    "#         print(x.shape)\n",
    "#         y = self.l3(y)\n",
    "#         print(x.shape)\n",
    "#         z = torch.cat([x,y],1)\n",
    "#         print(x.shape)\n",
    "#         z = self.fc(z)\n",
    "        x = self.conv(img)\n",
    "        print(x.shape)\n",
    "        x = x.view(-1, 2*self.base_size * (self.input_size // 4) * (self.input_size // 4))\n",
    "        print(x.shape)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class discriminator(nn.Module):\n",
    "    # Network Architecture is exactly same as in infoGAN (https://arxiv.org/abs/1606.03657)\n",
    "    # Architecture : (64)4c2s-(128)4c2s_BL-FC1024_BL-FC1_S\n",
    "    def __init__(self, input_dim=1, output_dim=1, input_size=32,base_size=64):\n",
    "        super(discriminator, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.input_size = 28\n",
    "        self.base_size = base_size\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(self.input_dim, self.base_size, 4, 2, 1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(self.base_size, 2*self.base_size, 4, 2, 1),\n",
    "            nn.BatchNorm2d(2*self.base_size),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(2*self.base_size * (self.input_size // 4) * (self.input_size // 4), 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(1024, self.output_dim),  # Note: no activation at the output.\n",
    "        )\n",
    "        initialize_weights(self)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.conv(input)\n",
    "        x = x.view(-1, 2*self.base_size * (self.input_size // 4) * (self.input_size // 4))\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(net):\n",
    "    for m in net.modules():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            m.weight.data.normal_(0, 0.02)\n",
    "            m.bias.data.zero_()\n",
    "        elif isinstance(m, nn.ConvTranspose2d):\n",
    "            m.weight.data.normal_(0, 0.02)\n",
    "            m.bias.data.zero_()\n",
    "        elif isinstance(m, nn.Linear):\n",
    "            m.weight.data.normal_(0, 0.02)\n",
    "            m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN():\n",
    "    def __init__(self, params):\n",
    "        \"\"\"Generative Adversarial Network class for learning how to control a self driving car with Bernstein polynomials\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        params : dict\n",
    "            Dictionary containing the parameters of the problem.\n",
    "                * max_epochs - Maximum number of epochs\n",
    "                * z_dim\n",
    "                * base_size\n",
    "                * lr_g - Generator learning rate\n",
    "                * lr_d - Discriminator learning rate\n",
    "                * beta1\n",
    "                * beta2\n",
    "        Returns\n",
    "        -------\n",
    "        numpy.array\n",
    "            1D vectory containing the initial guess for the optimizer. See above\n",
    "            description for the layout of the vector.\n",
    "        \"\"\"\n",
    "        # parameters\n",
    "        self.epoch = params['max_epochs']\n",
    "        self.sample_num = 100\n",
    "        self.batch_size = 300\n",
    "        self.input_size = 300\n",
    "        self.z_dim = params['z_dim']\n",
    "        self.base_size = params['base_size']\n",
    "\n",
    "        # load dataset\n",
    "#         self.data_loader = torch.utils.data.DataLoader(mnist_data_reduced, \n",
    "#                                                batch_size=self.batch_size, \n",
    "#                                                shuffle=True)\n",
    "        self.create_data_loader()\n",
    "        data = self.data_loader.__iter__().__next__()[0]\n",
    "\n",
    "        # initialization of the generator and discriminator\n",
    "        self.G = generator(input_dim=self.z_dim, output_dim=data.shape[1], input_size=self.input_size,base_size=self.base_size).cuda()\n",
    "        self.D = discriminator(input_dim=data.shape[1], output_dim=1, input_size=self.input_size,base_size=self.base_size).cuda()\n",
    "        self.G_optimizer = optim.Adam(self.G.parameters(), lr=params['lr_g'], betas=(params['beta1'], params['beta2']))\n",
    "        self.D_optimizer = optim.Adam(self.D.parameters(), lr=params['lr_d'], betas=(params['beta1'], params['beta2']))\n",
    "        #self.G_optimizer = optim.SGD(self.G.parameters(), lr=params['lr_g'], momentum=0.9)\n",
    "        #self.D_optimizer = optim.SGD(self.D.parameters(), lr=params['lr_d'], momentum=0.9)\n",
    "        \n",
    "        # initialization of the loss function\n",
    "        self.BCE_loss = nn.BCELoss().cuda()\n",
    "        self.MSE_loss = nn.MSELoss().cuda()\n",
    "        \n",
    "        # Gettng a batch of noise to generate the fake data\n",
    "        self.sample_z_ = torch.rand((self.batch_size, self.z_dim)).cuda()\n",
    "        \n",
    "    def create_data_loader(self):\n",
    "        self.data_loader = torch.utils.data.DataLoader(mnist_data_reduced, \n",
    "                                                       batch_size=self.batch_size, \n",
    "                                                       shuffle=True)\n",
    "        \n",
    "    #--------------------------------------------------------------------------------------------------------\n",
    "    # Fucntion to train the GAN, where you alternate between the training of the genenator and discriminator\n",
    "    def train(self):\n",
    "\n",
    "       # Setting empty arrays for storing the losses\n",
    "        self.train_hist = {}\n",
    "        self.train_hist['D_loss'] = []\n",
    "        self.train_hist['G_loss'] = []\n",
    "\n",
    "        # Setting up the labels for real and fake images\n",
    "        self.y_real_, self.y_fake_ = torch.ones(self.batch_size, 1).cuda(), torch.zeros(self.batch_size, 1).cuda()\n",
    "        \n",
    "        print('training start!!')\n",
    "\n",
    "        # Epoch loops\n",
    "        for epoch in range(self.epoch):\n",
    "            epoch_start_time = time.time()\n",
    "\n",
    "\n",
    "            for iter, (x_, _) in enumerate(self.data_loader):\n",
    "                if iter == self.data_loader.dataset.__len__() // self.batch_size:\n",
    "                    break\n",
    "\n",
    "                # Generate random noise to push through the generator   \n",
    "                z_ = torch.rand((self.batch_size, self.z_dim))\n",
    "                x_, z_ = x_.cuda(), z_.cuda()\n",
    "\n",
    "                # update D network\n",
    "                for i in range(Ninner):\n",
    "                    self.D_optimizer.zero_grad()\n",
    "                    x_ = x_  + 0.025 * torch.randn(x_.shape).cuda()\n",
    "                    D_real = self.D(x_)\n",
    "                    D_real_loss = self.BCE_loss(D_real, self.y_real_)\n",
    "\n",
    "                    G_ = self.G(z_)\n",
    "                    D_fake = self.D(G_)\n",
    "                    D_fake_loss = self.BCE_loss(D_fake, self.y_fake_)\n",
    "\n",
    "                    D_loss = D_real_loss + D_fake_loss\n",
    "                    D_loss.backward()\n",
    "                    self.D_optimizer.step()    \n",
    "\n",
    "                # update G network\n",
    "                for i in range(Ninner):\n",
    "                    self.G_optimizer.zero_grad()\n",
    "                    G_ = self.G(z_)\n",
    "                    D_fake = self.D(G_)\n",
    "                    G_loss = self.BCE_loss(D_fake, self.y_real_)\n",
    "\n",
    "                    G_loss.backward()\n",
    "                    self.G_optimizer.step()\n",
    "\n",
    "                self.train_hist['D_loss'].append(D_loss.item())\n",
    "                self.train_hist['G_loss'].append(G_loss.item())\n",
    "\n",
    "                # Print iterations and losses\n",
    "                if ((iter + 1) % 50) == 0:\n",
    "                    print(\"Epoch: [%2d] [%4d/%4d] D_loss: %.8f, G_loss: %.8f\" %\n",
    "                    ((epoch + 1), (iter + 1), self.data_loader.dataset.__len__() // self.batch_size, D_loss.item(), G_loss.item()))\n",
    "                \n",
    "            # Visualize results\n",
    "            with torch.no_grad():\n",
    "                visualize_results(self)\n",
    "\n",
    "        print(\"Training finished!\")\n",
    "\n",
    "    def train_ae(self):\n",
    "        torch.manual_seed(42)\n",
    "        criterion = nn.MSELoss() # mean square error loss\n",
    "        #optimizer = torch.optim.Adam(\n",
    "            #model.params(), lr=learning_rate, weight_decay=1e-4)\n",
    "\n",
    "        #train_loader = torch.utils.data.DataLoader(mnist_data_reduced, \n",
    "                                                  #batch_size=batch_size, \n",
    "                                                  #shuffle=True)\n",
    "        models = []\n",
    "        for epoch in range(self.epoch):\n",
    "            for data in self.data_loader:\n",
    "                img, _ = data\n",
    "                img = Variable(img).cuda().type(torch.cuda.FloatTensor)\n",
    "                recon = self.G(self.D(img))\n",
    "                loss = criterion(recon, img)\n",
    "                self.D_optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.D_optimizer.step()\n",
    "        \n",
    "            # Saving the models at each epoch for visualization purposes\n",
    "            #fname = 'dict'+str(epoch)\n",
    "            #torch.save(model.state_dict(), fname)\n",
    "            print('Epoch:{}, Loss:{:.4f}'.format(epoch+1, float(loss))) \n",
    "\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mnist_data_reduced' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-0fa687994f5f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'base_size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mgan\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGAN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mgan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-24-c07a90cbe572>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;31m# load dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         self.data_loader = torch.utils.data.DataLoader(mnist_data_reduced, \n\u001b[0m\u001b[0;32m     13\u001b[0m                                                \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                                                shuffle=True)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mnist_data_reduced' is not defined"
     ]
    }
   ],
   "source": [
    "params = {'beta1': 0.5, 'beta2': 0.999,'lr_g':0.0009,'lr_d':0.0009,'max_epochs':5} \n",
    "params['z_dim'] =2\n",
    "params['base_size'] = 64 \n",
    "\n",
    "gan = GAN(params)\n",
    "gan.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts = np.random.rand(len(bebot_data), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(219, 2)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "219"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bebot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = DataLoader(TensorDataset(Tensor(np.array(list(bebot_data.values())))), batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataLoader' object is not an iterator",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-0b4bc1fdfd69>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'DataLoader' object is not an iterator"
     ]
    }
   ],
   "source": [
    "next(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([219, 22])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tensor(np.array(list(bebot_data.values()))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
